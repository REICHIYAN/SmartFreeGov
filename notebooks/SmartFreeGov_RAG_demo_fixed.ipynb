{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49dcf320",
   "metadata": {
    "id": "49dcf320"
   },
   "source": [
    "# ğŸ›ï¸ SmartFreeGov - RAG FAQ Demo\n",
    "\n",
    "BigQuery + GPT-4 ã«ã‚ˆã‚‹è¡Œæ”¿FAQè‡ªå‹•å¿œç­”ãƒ‡ãƒ¢ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2281c86",
   "metadata": {
    "id": "e2281c86"
   },
   "outputs": [],
   "source": [
    "# âœ… å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæœ€åˆã®1å›ã ã‘ï¼‰\n",
    "!pip install openai google-cloud-bigquery python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142af79",
   "metadata": {
    "id": "4142af79"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# APIã‚­ãƒ¼ã¯æ‰‹å…¥åŠ›ï¼ˆã‚»ã‚­ãƒ¥ã‚¢ï¼‰\n",
    "OPENAI_API_KEY = input(\"ğŸ”‘ OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆè¡¨ç¤ºã•ã‚Œã¾ã™ï¼‰: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä»»ã›ã‚‹\n",
    "os.environ['BQ_PROJECT_ID'] = input(\"ğŸ§  BigQueryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: \")\n",
    "os.environ['BQ_DATASET_ID'] = input(\"ğŸ“¦ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: \")\n",
    "os.environ['BQ_TABLE_NAME'] = input(\"ğŸ“„ ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98426c46",
   "metadata": {
    "id": "98426c46"
   },
   "outputs": [],
   "source": [
    "# âœ… GPTå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆv1å¯¾å¿œï¼‰\n",
    "from openai import OpenAI\n",
    "\n",
    "def call_chatgpt(prompt):\n",
    "    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ã‚ãªãŸã¯è¡Œæ”¿FAQã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f352ae",
   "metadata": {
    "id": "b0f352ae"
   },
   "outputs": [],
   "source": [
    "# ğŸ”° æ‰‹å…ƒã§ä½œæˆã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # ambient-empire-xyz.json ã‚’ã‚¢ãƒƒãƒ—\n",
    "\n",
    "# ğŸ”‘ èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/your_key.json\"\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959a76a",
   "metadata": {
    "id": "6959a76a"
   },
   "outputs": [],
   "source": [
    "# âœ… BigQuery ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆï¼‹æ¤œç´¢ï¼‹cosineé¡ä¼¼åº¦è¨ˆç®—\n",
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "client = bigquery.Client(project=os.environ['BQ_PROJECT_ID'])\n",
    "full_table = f\"{os.environ['BQ_PROJECT_ID']}.{os.environ['BQ_DATASET_ID']}.{os.environ['BQ_TABLE_NAME']}\"\n",
    "query = f\"SELECT question, answer, embedding FROM `{full_table}`\"\n",
    "rows = client.query(query).result()\n",
    "\n",
    "user_query = \"ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ãŸã„\"\n",
    "user_embedding = np.random.rand(384)\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))\n",
    "\n",
    "results = []\n",
    "for row in rows:\n",
    "    emb = row['embedding']\n",
    "    if isinstance(emb, str):\n",
    "        emb = ast.literal_eval(emb)\n",
    "    score = cosine_similarity(user_embedding, emb)\n",
    "    results.append((score, row['question'], row['answer']))\n",
    "\n",
    "results.sort(reverse=True)\n",
    "top_3 = results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb129472",
   "metadata": {
    "id": "bb129472"
   },
   "outputs": [],
   "source": [
    "# âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ\n",
    "prompt = \"ã‚ãªãŸã¯FAQã«è©³ã—ã„å¸‚å½¹æ‰€ã®AIæ¡ˆå†…ä¿‚ã§ã™ã€‚\\nä»¥ä¸‹ã¯éå»ã®é¡ä¼¼è³ªå•ã¨ãã®å›ç­”ã§ã™ã€‚å‚è€ƒã«ã—ã¦ã€ã§ãã‚‹ã ã‘ç°¡æ½”ã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\\n\\n<FAQ>\\n\"\n",
    "for i, (_, q, a) in enumerate(top_3, 1):\n",
    "    prompt += f\"Q{i}: {q}\\nA{i}: {a}\\n\\n\"\n",
    "prompt += \"</FAQ>\\n\\nQ: \" + user_query + \"\\nA:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f27a7d",
   "metadata": {
    "id": "90f27a7d"
   },
   "outputs": [],
   "source": [
    "# âœ… å›ç­”ç”Ÿæˆ\n",
    "answer = call_chatgpt(prompt)\n",
    "print(\"\\n===== å›ç­” =====\\n\", answer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1tcDhMD1OHs8mp7tn6sb4P5WCcPuNko3-",
     "timestamp": 1751808122112
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
